# Social-Sensing-Womens-Health-TikTok
This repository contains the data for our Fall 2021 social sensing project.

Data Collection:
  As part of this project, we collected TikToks using hashtags relevant to women*’s health. We selected our hashtags based upon a list of health topics published by the U.S. Department of Health and Human Services, Office on Women’s Health. This list provided us insights into areas of health and disease that disproportionately affect women, and from there, we chose the following 16 hashtags: #birthcontrol, #birthcontrolsideeffects, #breastcancer, #cervicalcancer, #endometriosis, #fibroids, #hysterectomy, #infertilityjourney, #ovariancancer, #papsmear, #pcos, #pelvicfloor, #pms, #uterinecancer, #uti, and #utiremedies. To mitigate any personalization of videos presented to a user, we created a brand new TikTok account. Once we created the account, our process for collecting TikTok links involved searching a given hashtag and collecting the 50 most popular videos. We collected 50 videos each for the 16 hashtags, giving us 800 TikToks that will be analyzed in our project.
  The data collected appears to represent primarily English and American demographics. Furthermore, we recognize that women*’s health encompasses much more than reproductive health, but for the scoping of this project, we decided to limit the number of hashtags to 16. In a later phase of this project, we hope to discover a way to collect comments related to these TikToks to perform sentiment analysis regarding the dissemination of women*’s health information on TikTok. 

Codebook:
  Our second initial result of the project is the development of a preliminary codebook and coding instrument. We decided on the concepts we would like to investigate and selected measurable variables for each. Each coder will use the same coding instrument, an excel sheet with columns for each variable and rows for each video, so that intercoder reliability can be calculated and for ease of data analysis later. Coders first select Y (yes) and N (no) for the video’s relevance to the study. If N (no), no further data is collected. If Y (yes) to relevance, then the coder would select the condition being discussed, which in most cases will align with the hashtag by which the video was collected. To characterize the demographics of who is sharing information, coders then record the creator type: medical professional, patient, family/support, or lay person. Creator perceived age (Under 25, Over 25) and gender (M, F, Trans*, Unknown) will also be recorded, as well as video length. The number of likes, shares, and comments will be recorded to assess engagement. Then, coders will determine the type of video: personal testimony, medical visit narrative, raising awareness - medical professional, raising awareness - lay person, or humor. These categories are subject to change after the first round of coding, where each of the 3 coders will code the same 50 videos. A quantitative score of video information accuracy (misinformation) will be assessed using the DISCERN quality criteria (1-3), and understandability will be assessed using the Patient Materials Assessment Tool (1-3). Intercoder reliability will be assessed after the first 50 videos are coded to minimize the subjectivity of classification. Themes will be generated using a grounded theory approach, where each of the 3 coders in the first coding phase will determine the thematic content appearing in the videos, then discuss and set a codebook and controlled vocabulary of themes to apply to the rest of the dataset. After it is determined that there is intercoder reliability, the three coders will each code 250 videos. 
